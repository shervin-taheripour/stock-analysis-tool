{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22d2b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# (optional) speed companion\u001b[39;00m\n\u001b[32m     86\u001b[39m parq_path = DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33mindicators_wide.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43mwide\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparq_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m long_path, parq_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sherv\\workingdir\\Projects\\stock_analysis_tool\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sherv\\workingdir\\Projects\\stock_analysis_tool\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:3118\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[39m\n\u001b[32m   3037\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3038\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3039\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3114\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3115\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3116\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sherv\\workingdir\\Projects\\stock_analysis_tool\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:478\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    477\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    482\u001b[39m impl.write(\n\u001b[32m    483\u001b[39m     df,\n\u001b[32m    484\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     **kwargs,\n\u001b[32m    491\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sherv\\workingdir\\Projects\\stock_analysis_tool\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ohlcv_path = DATA_DIR / \"ohlcv.csv\"  # expected from masterframes_ingestion.ipynb\n",
    "df = pd.read_csv(ohlcv_path)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values([\"ticker\",\"date\"])\n",
    "\n",
    "# --- helpers ---\n",
    "def rsi14(close):\n",
    "    delta = close.diff()\n",
    "    up = delta.clip(lower=0.0)\n",
    "    dn = -delta.clip(upper=0.0)\n",
    "    roll_up = up.ewm(alpha=1/14, adjust=False).mean()\n",
    "    roll_dn = dn.ewm(alpha=1/14, adjust=False).mean()\n",
    "    rs = roll_up / roll_dn.replace(0, np.nan)\n",
    "    return 100 - (100/(1+rs))\n",
    "\n",
    "def macd(close, fast=12, slow=26, signal=9):\n",
    "    ema_fast = close.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = close.ewm(span=slow, adjust=False).mean()\n",
    "    line = ema_fast - ema_slow\n",
    "    sig  = line.ewm(span=signal, adjust=False).mean()\n",
    "    hist = line - sig\n",
    "    return line, sig, hist\n",
    "\n",
    "def rolling_vol(ret, win):\n",
    "    return ret.rolling(win).std() * np.sqrt(252)\n",
    "\n",
    "# daily returns\n",
    "df[\"ret\"] = df.groupby(\"ticker\")[\"close\"].pct_change()\n",
    "\n",
    "# compute per ticker\n",
    "out = []\n",
    "tickers = df[\"ticker\"].unique().tolist()\n",
    "has_spy = \"SPY\" in tickers\n",
    "spy_ret = None\n",
    "\n",
    "if has_spy:\n",
    "    spy = df[df[\"ticker\"]==\"SPY\"][[\"date\",\"ret\"]].rename(columns={\"ret\":\"ret_spy\"})\n",
    "    spy_ret = spy.set_index(\"date\")[\"ret_spy\"]\n",
    "\n",
    "for tk, g in df.groupby(\"ticker\", sort=False):\n",
    "    g = g.sort_values(\"date\").set_index(\"date\")\n",
    "    close = g[\"close\"]\n",
    "\n",
    "    rec = pd.DataFrame(index=g.index)\n",
    "    rec[\"ticker\"] = tk\n",
    "    rec[\"sma20\"] = close.rolling(20).mean()\n",
    "    rec[\"sma50\"] = close.rolling(50).mean()\n",
    "    rec[\"ema20\"] = close.ewm(span=20, adjust=False).mean()\n",
    "    rec[\"ema50\"] = close.ewm(span=50, adjust=False).mean()\n",
    "    rec[\"rsi14\"] = rsi14(close)\n",
    "\n",
    "    line, sig, hist = macd(close)\n",
    "    rec[\"macd_line\"] = line\n",
    "    rec[\"macd_signal\"] = sig\n",
    "    rec[\"macd_hist\"] = hist\n",
    "\n",
    "    rec[\"vol20\"] = rolling_vol(g[\"ret\"], 20)\n",
    "    rec[\"vol60\"] = rolling_vol(g[\"ret\"], 60)\n",
    "\n",
    "    if has_spy and tk != \"SPY\":\n",
    "        joined = pd.concat([g[\"ret\"], spy_ret], axis=1).dropna()\n",
    "        joined.columns = [\"ret_tk\",\"ret_spy\"]\n",
    "        corr60 = joined[\"ret_tk\"].rolling(60).corr(joined[\"ret_spy\"])\n",
    "        rec[\"rollcorr60_spy\"] = corr60.reindex(rec.index)\n",
    "    else:\n",
    "        rec[\"rollcorr60_spy\"] = np.nan\n",
    "\n",
    "    rec = rec.reset_index().rename(columns={\"index\":\"date\"})\n",
    "    out.append(rec)\n",
    "\n",
    "wide = pd.concat(out, ignore_index=True)\n",
    "# long-form (ticker, date, metric, value)\n",
    "long = wide.melt(id_vars=[\"ticker\",\"date\"], var_name=\"metric\", value_name=\"value\")\n",
    "\n",
    "# persist ONE canonical table (long form)\n",
    "long_path = DATA_DIR / \"indicators.csv\"\n",
    "long.to_csv(long_path, index=False)\n",
    "\n",
    "# (optional) speed companion\n",
    "parq_path = DATA_DIR / \"indicators_wide.parquet\"\n",
    "wide.to_parquet(parq_path, index=False)\n",
    "\n",
    "long_path, parq_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
